{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2a8fff-4124-4c6d-9258-c05657ec01c8",
   "metadata": {},
   "source": [
    "# Lesson 6. Model evaluation\n",
    "\n",
    "The model comparison tool that Sung described in the video can be found at this link: https://console.upstage.ai/ (note that you need to create a free account to try it out.)\n",
    "\n",
    "A useful tool for evaluating LLMs is the **LM Evaluation Harness** built by EleutherAI. Information about the harness can be found at this [github repo](https://github.com/EleutherAI/lm-evaluation-harness):\n",
    "\n",
    "You can run the commented code below to install the evaluation harness in your own environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31fbf66-c7d5-4323-8f8a-acda7a12f66b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!pip install -U git+https://github.com/EleutherAI/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b1cfc",
   "metadata": {},
   "source": [
    "You will evaluate TinySolar-248m-4k on 5 questions from the **TruthfulQA MC2 task**. This is a multiple-choice question answering task that tests the model's ability to identify true statements. You can read more about the TruthfulQA benchmark in [this paper](https://arxiv.org/abs/2109.07958), and you can checkout the code for implementing the tasks at this [github repo](https://github.com/sylinrl/TruthfulQA).\n",
    "\n",
    "The code below runs only the TruthfulQA MC2 task using the LM Evaluation Harness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c2c258-98de-43c7-9b96-cce7a6f20024",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05:00:38:12,098 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-03-05:00:38:12,099 INFO     [lm_eval.__main__:379] Selected Tasks: ['truthfulqa_mc2']\n",
      "2025-03-05:00:38:12,102 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-03-05:00:38:12,102 INFO     [lm_eval.evaluator:206] Initializing hf model, with arguments: {'pretrained': 'upstage/TinySolar-248m-4k'}\n",
      "2025-03-05:00:38:12,126 INFO     [lm_eval.models.huggingface:136] Using device 'cpu'\n",
      "2025-03-05:00:38:12,995 INFO     [lm_eval.models.huggingface:376] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cpu'}\n",
      "Downloading readme: 100%|██████████████████| 9.59k/9.59k [00:00<00:00, 20.9MB/s]\n",
      "Downloading data:   0%|                              | 0.00/271k [00:00<?, ?B/s]Traceback (most recent call last):\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connection.py\", line 464, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/http/client.py\", line 1428, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/http/client.py\", line 331, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/http/client.py\", line 292, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/util/util.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 538, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 369, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/__main__.py\", line 389, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/utils.py\", line 422, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/evaluator.py\", line 240, in simple_evaluate\n",
      "    task_dict = get_task_dict(tasks, task_manager)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/tasks/__init__.py\", line 619, in get_task_dict\n",
      "    task_name_from_string_dict = task_manager.load_task_or_group(\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/tasks/__init__.py\", line 415, in load_task_or_group\n",
      "    collections.ChainMap(*map(self._load_individual_task_or_group, task_list))\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/tasks/__init__.py\", line 315, in _load_individual_task_or_group\n",
      "    return _load_task(task_config, task=name_or_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/tasks/__init__.py\", line 281, in _load_task\n",
      "    task_object = ConfigurableTask(config=config)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/api/task.py\", line 823, in __init__\n",
      "    self.download(self.config.dataset_kwargs)\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/lm_eval/api/task.py\", line 930, in download\n",
      "    self.dataset = datasets.load_dataset(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/load.py\", line 2549, in load_dataset\n",
      "    builder_instance.download_and_prepare(\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/builder.py\", line 1005, in download_and_prepare\n",
      "    self._download_and_prepare(\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/builder.py\", line 1078, in _download_and_prepare\n",
      "    split_generators = self._split_generators(dl_manager, **split_generators_kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/packaged_modules/parquet/parquet.py\", line 43, in _split_generators\n",
      "    data_files = dl_manager.download_and_extract(self.config.data_files)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/download/download_manager.py\", line 562, in download_and_extract\n",
      "    return self.extract(self.download(url_or_urls))\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/download/download_manager.py\", line 426, in download\n",
      "    downloaded_path_or_paths = map_nested(\n",
      "                               ^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/py_utils.py\", line 467, in map_nested\n",
      "    _single_map_nested((function, obj, types, None, True, None))\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/py_utils.py\", line 387, in _single_map_nested\n",
      "    mapped = [_single_map_nested((function, v, types, None, True, None)) for v in pbar]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/py_utils.py\", line 370, in _single_map_nested\n",
      "    return function(data_struct)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/download/download_manager.py\", line 451, in _download\n",
      "    out = cached_path(url_or_filename, download_config=download_config)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/file_utils.py\", line 188, in cached_path\n",
      "    output_path = get_from_cache(\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/file_utils.py\", line 616, in get_from_cache\n",
      "    fsspec_get(url, temp_file, storage_options=storage_options, desc=download_desc)\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/datasets/utils/file_utils.py\", line 340, in fsspec_get\n",
      "    fs.get_file(paths[0], temp_file.name, callback=callback)\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py\", line 896, in get_file\n",
      "    http_get(\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 371, in http_get\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 303, in _request_wrapper\n",
      "    response = get_session().request(method=method, url=url, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/sessions.py\", line 724, in send\n",
      "    history = [resp for resp in gen]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/sessions.py\", line 265, in resolve_redirects\n",
      "    resp = self.send(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/huggingface_hub/utils/_http.py\", line 96, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/andrewchiayj/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6aea1a8c-dc17-4a67-b4fc-7f970e7bc9e3)')\n",
      "Downloading data:   0%|                              | 0.00/271k [00:10<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=upstage/TinySolar-248m-4k \\\n",
    "    --tasks truthfulqa_mc2 \\\n",
    "    --device cpu \\\n",
    "    --limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeef916",
   "metadata": {},
   "source": [
    "### Evaluation for the Hugging Face Leaderboard\n",
    "You can use the code below to test your own model against the evaluations required for the [Hugging Face leaderboard](https://huggingface.co/open-llm-leaderboard). \n",
    "\n",
    "If you decide to run this evaluation on your own model, don't change the few-shot numbers below - they are set by the rules of the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc097be-7dbb-4a90-a954-f39d30e8e52c",
   "metadata": {
    "height": 404
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_namiiie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     14\u001b[0m     eval_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m    lm_eval --model hf \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m        --model_args pretrained=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_namiiie\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m        --num_fewshot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfewshot\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     os\u001b[38;5;241m.\u001b[39msystem(eval_cmd)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mh6_open_llm_leaderboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYOUR_MODEL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m, in \u001b[0;36mh6_open_llm_leaderboard\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m task_and_shot \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marc_challenge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m25\u001b[39m),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhellaswag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsm8k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task, fewshot \u001b[38;5;129;01min\u001b[39;00m task_and_shot:\n\u001b[1;32m     14\u001b[0m   eval_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m  lm_eval --model hf \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;124m      --model_args pretrained=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_namiiie\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m      --tasks \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m      --device cpu \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m      --num_fewshot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfewshot\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     21\u001b[0m   os\u001b[38;5;241m.\u001b[39msystem(eval_cmd)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_namiiie' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def h6_open_llm_leaderboard(model_name):\n",
    "  task_and_shot = [\n",
    "      ('arc_challenge', 25),\n",
    "      ('hellaswag', 10),\n",
    "      ('mmlu', 5),\n",
    "      ('truthfulqa_mc2', 0),\n",
    "      ('winogrande', 5),\n",
    "      ('gsm8k', 5)\n",
    "  ]\n",
    "\n",
    "  for task, fewshot in task_and_shot:\n",
    "    eval_cmd = f\"\"\"\n",
    "    lm_eval --model hf \\\n",
    "        --model_args pretrained={model_namiiie} \\\n",
    "        --tasks {task} \\\n",
    "        --device cpu \\\n",
    "        --num_fewshot {fewshot}\n",
    "    \"\"\"\n",
    "    os.system(eval_cmd)\n",
    "\n",
    "h6_open_llm_leaderboard(model_name=\"YOUR_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1d277-1148-4fed-bd02-ca7dad4ec8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
